{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3231b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv(\"books_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58634dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"genre\"].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb660cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "  \"Nonfiction\": \"Nonfiction\",\n",
    "  \"History\": \"Nonfiction\",\n",
    "  \"Games,Chess\": \"Nonfiction\",\n",
    "  \"Esoterica,Astrology\": \"Nonfiction\",\n",
    "  \"History,Nonfiction\": \"Nonfiction\",\n",
    "  \"Music\": \"Nonfiction\",\n",
    "  \"Combat,Martial Arts\": \"Nonfiction\",\n",
    "  \"Crafts,Quilting\": \"Nonfiction\",\n",
    "  \"Science,Mathematics\": \"Nonfiction\",\n",
    "  \"Art\": \"Nonfiction\",\n",
    "  \"Poetry\": \"Fiction\",\n",
    "  \"Nurses,Nursing\": \"Nonfiction\",\n",
    "  \"Fiction\": \"Fiction\",\n",
    "  \"Occult,Tarot\": \"Nonfiction\",\n",
    "  \"Romance,Romance,African American Romance\": \"Fiction\",\n",
    "  \"Childrens\": \"Fiction\",\n",
    "  \"Reference\": \"Nonfiction\",\n",
    "  \"Alcohol,Wine\": \"Nonfiction\",\n",
    "  \"Philosophy\": \"Nonfiction\",\n",
    "  \"Romance\": \"Fiction\",\n",
    "  \"Literature,Marathi\": \"Fiction\",\n",
    "  \"Crafts,Origami\": \"Nonfiction\",\n",
    "  \"Architecture\": \"Nonfiction\",\n",
    "  \"Nonfiction,History\": \"Nonfiction\",\n",
    "  \"Travel\": \"Nonfiction\",\n",
    "  \"Science\": \"Nonfiction\",\n",
    "  \"Romance,African American Romance\": \"Fiction\",\n",
    "  \"Crafts,Sewing\": \"Nonfiction\",\n",
    "  \"Cultural,Africa\": \"Nonfiction\",\n",
    "  \"Spirituality\": \"Nonfiction\",\n",
    "  \"Crafts,Knitting,Art,Crafts,Nonfiction\": \"Nonfiction\",\n",
    "  \"Social Science,Social Work\": \"Nonfiction\",\n",
    "  \"Food and Drink,Cookbooks\": \"Nonfiction\",\n",
    "  \"Romance,African American Romance,Romance\": \"Fiction\",\n",
    "  \"Gardening,Nonfiction\": \"Nonfiction\",\n",
    "  \"Couture,Fashion\": \"Nonfiction\",\n",
    "  \"Childrens,Picture Books,Childrens\": \"Fiction\",\n",
    "  \"Aviation\": \"Nonfiction\",\n",
    "  \"Crafts,Knitting,Nonfiction,Art,Crafts\": \"Nonfiction\",\n",
    "  \"Gardening\": \"Nonfiction\",\n",
    "  \"Crafts,Crochet\": \"Nonfiction\",\n",
    "  \"Games,Role Playing Games\": \"Fiction\",\n",
    "  \"Biography\": \"Nonfiction\",\n",
    "  \"Business\": \"Nonfiction\",\n",
    "  \"Religion\": \"Nonfiction\",\n",
    "  \"Science,Chemistry\": \"Nonfiction\",\n",
    "  \"Art,Art,Drawing\": \"Nonfiction\",\n",
    "  \"Labor\": \"Nonfiction\",\n",
    "  \"Art,Crafts\": \"Nonfiction\",\n",
    "  \"Sports,Cycling\": \"Nonfiction\",\n",
    "  \"Sports,Baseball,Sports,Sports,Nonfiction\": \"Nonfiction\",\n",
    "  \"Fantasy\": \"Fiction\",\n",
    "  \"Mystery\": \"Fiction\",\n",
    "  \"Cultural,Iran\": \"Nonfiction\",\n",
    "  \"Childrens,Picture Books\": \"Fiction\",\n",
    "  \"Harlequin,Harlequin Romance\": \"Fiction\",\n",
    "  \"Games,Role Playing Games,Fantasy\": \"Fiction\",\n",
    "  \"Westerns\":\"Fiction\",\n",
    "  \"Westerns,Fiction\": \"Fiction\",\n",
    "  \"Asian Literature,Turkish Literature\": \"Fiction\",\n",
    "  \"Horror\": \"Fiction\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058225a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"simple_categories\"] = books[\"genre\"].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed112cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "isbns = []\n",
    "predicted_cats = []\n",
    "\n",
    "missing_cats = books.loc[books[\"simple_categories\"].isna(), [\"isbn\", \"desc\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8566c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def predict_fiction_nonfiction(text_list):\n",
    "    \"\"\"\n",
    "    Loads a fine-tuned DeBERTa model and predicts whether a list of texts\n",
    "    is Fiction or Non-fiction.\n",
    "\n",
    "    Args:\n",
    "        text_list (list of str): A list of texts to classify.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of predicted labels (\"Fiction\" or \"Nonfiction\").\n",
    "    \"\"\"\n",
    "    # Load the fine-tuned model and tokenizer\n",
    "    model_path = \"./final_model\"\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    except OSError:\n",
    "        print(f\"Error: Could not find a saved model and tokenizer at '{model_path}'.\")\n",
    "        print(\"Please make sure you have run the training script and the model was saved correctly.\")\n",
    "        return []\n",
    "\n",
    "    # Set up the device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded on: {device}\")\n",
    "\n",
    "    # Tokenize the input texts\n",
    "    print(\"Tokenizing input...\")\n",
    "    inputs = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Move tensors to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Get predictions\n",
    "    print(\"Getting predictions...\")\n",
    "    with torch.no_grad(): \n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    predictions_cpu = predictions.cpu().numpy()\n",
    "\n",
    "    # Decode the predictions to labels\n",
    "    id2label = model.config.id2label\n",
    "    predicted_labels = [id2label[idx] for idx in predictions_cpu]\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(0, len(missing_cats))):\n",
    "    sequence = missing_cats[\"desc\"][i]\n",
    "    predicted_cats += [predict_fiction_nonfiction([sequence])]\n",
    "    isbns += [missing_cats[\"isbn\"][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_predicted_df = pd.DataFrame({\"isbn\": isbns, \"predicted_categories\": predicted_cats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "books = pd.merge(books, missing_predicted_df, on=\"isbn\", how=\"left\")\n",
    "books[\"simple_categories\"] = np.where(books[\"simple_categories\"].isna(), books[\"predicted_categories\"], books[\"simple_categories\"])\n",
    "books = books.drop(columns = [\"predicted_categories\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"books_with_categories.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
